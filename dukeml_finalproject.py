# -*- coding: utf-8 -*-
"""DukeML_FinalProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18A0vL5pxsBYnP33kaCABqGU5M3nRjKcW
"""

from google.colab import files
uploaded = files.upload()

import io
import pandas as pd
filename = list(uploaded.keys())[0]
df = pd.read_csv(io.BytesIO(uploaded[filename]))

print("Shape:", df.shape)
print("\nColumn types:\n", df.dtypes)
print("\nFirst 5 rows:")
display(df.head())

print("\nSummary statistics:")
display(df.describe())
print("\nMissing values per column:")
print(df.isnull().sum())

import matplotlib.pyplot as plt

features = ['AT', 'AP', 'RH', 'V']

for feat in features:
    plt.figure()
    plt.hist(df[feat], bins=30, edgecolor='black')
    plt.title(f'Histogram of {feat}')
    plt.xlabel(feat)
    plt.ylabel('Frequency')
    plt.show()

for feat in features:
    plt.figure()
    plt.scatter(df[feat], df['PE'])
    plt.title(f'PE vs. {feat}')
    plt.xlabel(feat)
    plt.ylabel('Net Hourly Electrical Energy Output (PE)')
    plt.show()

from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
import numpy as np

features = ['AT', 'AP', 'RH', 'V']
X = df[features]
y = df['PE']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
print("Train:", X_train.shape, "Test:", X_test.shape)

kf = KFold(n_splits=5, shuffle=True, random_state=42)

lr_pipe = Pipeline([
    ('scale', StandardScaler()),
    ('lr',   LinearRegression())
])
lr_scores = cross_val_score(
    lr_pipe, X_train, y_train,
    scoring='neg_mean_squared_error',
    cv=kf
)
lr_rmse = np.sqrt(-lr_scores)
print(f"Linear Regression CV RMSE: {lr_rmse.mean():.3f} ± {lr_rmse.std():.3f}")

rf_pipe = Pipeline([
    ('rf', RandomForestRegressor(random_state=42))
])
rf_scores = cross_val_score(
    rf_pipe, X_train, y_train,
    scoring='neg_mean_squared_error',
    cv=kf
)
rf_rmse = np.sqrt(-rf_scores)
print(f"Random Forest CV RMSE:   {rf_rmse.mean():.3f} ± {rf_rmse.std():.3f}")

from sklearn.metrics import mean_squared_error, r2_score

rf_pipe.fit(X_train, y_train)

y_pred = rf_pipe.predict(X_test)

test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))

test_r2   = r2_score(y_test, y_pred)

print(f"Test RMSE: {test_rmse:.3f} MW")
print(f"Test R²:   {test_r2:.3f}")

importances = rf_pipe.named_steps['rf'].feature_importances_
feat_imp = pd.Series(importances, index=features).sort_values(ascending=False)

print("Feature importances:")
print(feat_imp)

feat_imp.plot.bar(title="Feature Importances"); plt.ylabel("Importance"); plt.show()

